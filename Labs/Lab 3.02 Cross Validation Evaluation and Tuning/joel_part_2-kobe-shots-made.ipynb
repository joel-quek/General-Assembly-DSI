{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "\n",
    "# Predicting Shots Made Per Game by Kobe Bryant\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab you'll be using regularized regression penalties — ridge, lasso, and elastic net — to try and predict how many shots Kobe Bryant made per game during his career.\n",
    "\n",
    "The Kobe Shots data set contains hundreds of columns representing different characteristics of each basketball game. Fitting an ordinary linear regression using every predictor would dramatically overfit the model, considering the limited number of observations (games) we have available. Plus, many of the predictors have significant multicollinearity. \n",
    "\n",
    "\n",
    "**Warning:** Some of these calculations are computationally expensive and may take a while to execute. It may be worthwhile to only use a portion of the data to perform these calculations, especially if you've experienced kernel issues in the past.\n",
    "\n",
    "---\n",
    "\n",
    "### 1) Load packages and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import patsy\n",
    "\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kobe = pd.read_csv('./datasets/kobe_superwide_games.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Examine the data.\n",
    "\n",
    "- How many columns are there?\n",
    "- Examine what the observations (rows) and columns represent.\n",
    "- Why might regularization be particularly useful for modeling this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SHOTS_MADE</th>\n",
       "      <th>AWAY_GAME</th>\n",
       "      <th>SEASON_OPPONENT:atl:1996-97</th>\n",
       "      <th>SEASON_OPPONENT:atl:1997-98</th>\n",
       "      <th>SEASON_OPPONENT:atl:1999-00</th>\n",
       "      <th>SEASON_OPPONENT:atl:2000-01</th>\n",
       "      <th>SEASON_OPPONENT:atl:2001-02</th>\n",
       "      <th>SEASON_OPPONENT:atl:2002-03</th>\n",
       "      <th>SEASON_OPPONENT:atl:2003-04</th>\n",
       "      <th>SEASON_OPPONENT:atl:2004-05</th>\n",
       "      <th>...</th>\n",
       "      <th>ACTION_TYPE:tip_layup_shot</th>\n",
       "      <th>ACTION_TYPE:tip_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_bank_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_fadeaway_bank_jump_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_fadeaway_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_finger_roll_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_hook_shot</th>\n",
       "      <th>ACTION_TYPE:turnaround_jump_shot</th>\n",
       "      <th>SEASON_GAME_NUMBER</th>\n",
       "      <th>CAREER_GAME_NUMBER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 645 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SHOTS_MADE  AWAY_GAME  SEASON_OPPONENT:atl:1996-97  \\\n",
       "0         0.0          0                          0.0   \n",
       "1         0.0          1                          0.0   \n",
       "2         2.0          1                          0.0   \n",
       "3         2.0          1                          0.0   \n",
       "4         0.0          0                          1.0   \n",
       "\n",
       "   SEASON_OPPONENT:atl:1997-98  SEASON_OPPONENT:atl:1999-00  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   SEASON_OPPONENT:atl:2000-01  SEASON_OPPONENT:atl:2001-02  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   SEASON_OPPONENT:atl:2002-03  SEASON_OPPONENT:atl:2003-04  \\\n",
       "0                          0.0                          0.0   \n",
       "1                          0.0                          0.0   \n",
       "2                          0.0                          0.0   \n",
       "3                          0.0                          0.0   \n",
       "4                          0.0                          0.0   \n",
       "\n",
       "   SEASON_OPPONENT:atl:2004-05  ...  ACTION_TYPE:tip_layup_shot  \\\n",
       "0                          0.0  ...                         0.0   \n",
       "1                          0.0  ...                         0.0   \n",
       "2                          0.0  ...                         0.0   \n",
       "3                          0.0  ...                         0.0   \n",
       "4                          0.0  ...                         0.0   \n",
       "\n",
       "   ACTION_TYPE:tip_shot  ACTION_TYPE:turnaround_bank_shot  \\\n",
       "0                   0.0                               0.0   \n",
       "1                   0.0                               0.0   \n",
       "2                   0.0                               0.0   \n",
       "3                   0.0                               0.0   \n",
       "4                   0.0                               0.0   \n",
       "\n",
       "   ACTION_TYPE:turnaround_fadeaway_bank_jump_shot  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "\n",
       "   ACTION_TYPE:turnaround_fadeaway_shot  \\\n",
       "0                                   0.0   \n",
       "1                                   0.0   \n",
       "2                                   0.0   \n",
       "3                                   0.0   \n",
       "4                                   0.0   \n",
       "\n",
       "   ACTION_TYPE:turnaround_finger_roll_shot  ACTION_TYPE:turnaround_hook_shot  \\\n",
       "0                                      0.0                               0.0   \n",
       "1                                      0.0                               0.0   \n",
       "2                                      0.0                               0.0   \n",
       "3                                      0.0                               0.0   \n",
       "4                                      0.0                               0.0   \n",
       "\n",
       "   ACTION_TYPE:turnaround_jump_shot  SEASON_GAME_NUMBER  CAREER_GAME_NUMBER  \n",
       "0                               0.0                   1                   1  \n",
       "1                               0.0                   2                   2  \n",
       "2                               0.0                   3                   3  \n",
       "3                               0.0                   4                   4  \n",
       "4                               0.0                   5                   5  \n",
       "\n",
       "[5 rows x 645 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SHOTS_MADE', 'AWAY_GAME', 'SEASON_OPPONENT:atl:1996-97',\n",
       "       'SEASON_OPPONENT:atl:1997-98', 'SEASON_OPPONENT:atl:1999-00',\n",
       "       'SEASON_OPPONENT:atl:2000-01', 'SEASON_OPPONENT:atl:2001-02',\n",
       "       'SEASON_OPPONENT:atl:2002-03', 'SEASON_OPPONENT:atl:2003-04',\n",
       "       'SEASON_OPPONENT:atl:2004-05',\n",
       "       ...\n",
       "       'ACTION_TYPE:tip_layup_shot', 'ACTION_TYPE:tip_shot',\n",
       "       'ACTION_TYPE:turnaround_bank_shot',\n",
       "       'ACTION_TYPE:turnaround_fadeaway_bank_jump_shot',\n",
       "       'ACTION_TYPE:turnaround_fadeaway_shot',\n",
       "       'ACTION_TYPE:turnaround_finger_roll_shot',\n",
       "       'ACTION_TYPE:turnaround_hook_shot', 'ACTION_TYPE:turnaround_jump_shot',\n",
       "       'SEASON_GAME_NUMBER', 'CAREER_GAME_NUMBER'],\n",
       "      dtype='object', length=645)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kobe.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Create predictor and target variables. Standardize the predictors.\n",
    "\n",
    "Why is normalization necessary for regularized regressions?\n",
    "\n",
    "Use the `sklearn.preprocessing` class `StandardScaler` to standardize the predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictor(X) and Target(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= kobe.drop('SHOTS_MADE', axis=1)\n",
    "y=kobe['SHOTS_MADE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Scaled = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Build a linear regression predicting `SHOTS_MADE` from the rest of the columns.\n",
    "\n",
    "Cross-validate the $R^2$ of an ordinary linear regression model with 10 cross-validation folds.\n",
    "\n",
    "How does it perform?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-8.21974827e+28 -8.93366955e+27 -1.72949798e+27 -2.55961745e+27\n",
      " -4.41730145e+27 -6.82076677e+26 -3.23598335e+27 -1.69338500e+27\n",
      " -1.82179630e+27 -8.03804534e+27]\n",
      "-1.153088558418262e+28\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(model, X_Scaled,y,cv=10))\n",
    "print(np.mean(cross_val_score(model, X_Scaled,y,cv=10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negative $R^2$ scores mean the models are doing very badly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Find an optimal value for the ridge regression alpha using `RidgeCV`.\n",
    "\n",
    "Go to the documentation and [read how RidgeCV works](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html).\n",
    "\n",
    "> *Hint: Once the RidgeCV is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that ridge performs best when searching alphas through logarithmic space (`np.logspace`). This may take awhile to fit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Refer to Lecture 3.06**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = np.logspace(0, 5, 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source for Optimal Ridge Alpha \n",
    "\n",
    "https://chrisalbon.com/code/machine_learning/linear_regression/selecting_best_alpha_value_in_ridge_regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logspace\n",
    "\n",
    "https://www.geeksforgeeks.org/numpy-logspace-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = RidgeCV(alphas=ridge_alphas, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ridge = best_ridge.fit(X_Scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "775.2597488629465\n"
     ]
    }
   ],
   "source": [
    "print(best_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Alpha value is 775.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6) Cross-validate the ridge regression $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the linear regression? If so, why might this be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=775.2597488629465)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=775.2597488629465)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=775.2597488629465)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=775.2597488629465)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_model.fit(X_Scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5822626  0.52880462 0.4869004  0.59583817 0.52396335 0.52942952\n",
      " 0.52842192 0.41153448 0.39857643 0.44489752]\n",
      "0.5030628996817688\n"
     ]
    }
   ],
   "source": [
    "ridge_scores = cross_val_score(ridge_model, X_Scaled, y, cv=10)\n",
    "\n",
    "print (ridge_scores)\n",
    "print (np.mean(ridge_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the Linear Regression model had a $R^2$ score of -1.153088558418262e+28\n",
    " \n",
    "The Ridge Regularized model has a much better score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7) Find an optimal value for lasso regression alpha using `LassoCV`.\n",
    "\n",
    "Go to the documentation and [read how LassoCV works](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html). It is very similar to `RidgeCV`.\n",
    "\n",
    "> *Hint: Again, once the `LassoCV` is fit, the attribute `.alpha_` contains the best alpha parameter it found through cross-validation.*\n",
    "\n",
    "Recall that lasso, unlike ridge, performs best when searching for alpha through linear space (`np.linspace`). However, you can actually let the LassoCV decide what alphas to use itself by setting the keyword argument `n_alphas=` to however many alphas you want it to search over. We recommend letting scikit-learn choose the range of alphas.\n",
    "\n",
    "_**Tip:** If you find your CV taking a long time and you're not sure if it's working, set `verbose =1`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = LassoCV(n_alphas=500, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lasso = best_lasso.fit(X_Scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06790539979326354\n"
     ]
    }
   ],
   "source": [
    "print(best_lasso.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8) Cross-validate the lasso $R^2$ with the optimal alpha.\n",
    "\n",
    "Is it better than the linear regression? Is it better than ridge? What do the differences in results imply about the issues with the data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso_model = Lasso(alpha=0.06790539979326354)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.06790539979326354)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.06790539979326354)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.06790539979326354)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.fit(X_Scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61603625 0.52641159 0.53888743 0.61322432 0.54627539 0.5554072\n",
      " 0.52716822 0.44849563 0.4646267  0.51838952]\n",
      "0.5354922262084527\n"
     ]
    }
   ],
   "source": [
    "lasso_scores = cross_val_score(lasso_model, X_Scaled, y, cv=10)\n",
    "\n",
    "print (lasso_scores)\n",
    "print (np.mean(lasso_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso performs slightly better than Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9) Look at the coefficients for variables in the lasso.\n",
    "\n",
    "1. Show the coefficient for variables, ordered from largest to smallest coefficient by absolute value.\n",
    "2. What percent of the variables in the original data set are \"zeroed-out\" by the lasso?\n",
    "3. What are the most important predictors for how many shots Kobe made in a game?\n",
    "\n",
    "> **Note:** If you only fit the lasso within `cross_val_score`, you'll have to refit it outside of that function to pull out the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.06790539979326354)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.06790539979326354)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.06790539979326354)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.fit(X_Scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.82854323e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  6.49685832e-03,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  6.22608272e-03, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  4.92571783e-03, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.43490539e-02, -6.86717542e-02, -3.50481654e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00,  7.46060170e-03, -9.00601335e-03,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -8.91632555e-02,  0.00000000e+00,\n",
       "       -1.07292770e-02,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -8.27751260e-04, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.61760602e-02, -0.00000000e+00,  0.00000000e+00, -8.22328983e-03,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  4.75715566e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "        2.19473278e-03,  5.25812119e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  2.91743106e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -1.63264926e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -2.42712253e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  7.13978765e-02, -0.00000000e+00,\n",
       "       -8.33197827e-03, -1.64609721e-02,  0.00000000e+00,  1.66412513e-02,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  5.55573843e-02,\n",
       "        0.00000000e+00, -4.47125565e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -6.53655347e-03,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  4.01620431e-02,  6.27303239e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -4.05524379e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "       -2.26824451e-02, -0.00000000e+00, -0.00000000e+00,  2.77484765e-02,\n",
       "        1.21326547e-02, -0.00000000e+00,  0.00000000e+00, -5.21468706e-02,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        2.66065703e-02, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -2.61790567e-02,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -1.77217284e-03,  5.39045660e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -3.18274218e-02, -0.00000000e+00,\n",
       "       -0.00000000e+00, -4.24035448e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "       -2.76882378e-02, -0.00000000e+00,  0.00000000e+00,  4.82542311e-03,\n",
       "        0.00000000e+00,  2.10650278e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -2.37012382e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  1.91934225e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -1.08844838e-03,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  2.23828216e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "       -4.22311806e-02, -0.00000000e+00, -6.23841346e-03,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.16943871e-01, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        2.79353207e-03, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -2.91895146e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.53660231e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  3.54921100e-02, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  3.70989171e-04,\n",
       "       -1.79795150e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  2.25656204e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -5.91398487e-02,\n",
       "       -0.00000000e+00, -0.00000000e+00, -8.82887475e-03, -0.00000000e+00,\n",
       "       -1.62504613e-02,  0.00000000e+00,  0.00000000e+00,  2.12380936e-02,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -2.16275030e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -1.99605658e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  2.74918575e-02,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  1.11245143e-01,  4.90724700e-02,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.16913663e-03, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -3.46619616e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -2.81731924e-02,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.56871800e-02, -9.42342914e-03,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -1.44575349e-02, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  1.30148788e-02, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        5.74965175e-03, -3.23749857e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  2.99517578e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -3.10217033e-02,  3.60173666e-02,\n",
       "       -0.00000000e+00,  4.22137075e-02,  0.00000000e+00,  9.91997727e-02,\n",
       "        0.00000000e+00,  6.80440054e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        2.69187266e-02, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        3.58807899e-02,  1.26871725e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  1.16808000e-02, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  6.56247804e-03,  1.27064854e-01,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.89715571e-03,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -1.26388956e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  1.60060012e-02,  0.00000000e+00,\n",
       "        0.00000000e+00, -1.78058391e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "       -7.50738742e-02, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -1.05455706e-02, -4.11289753e-03,\n",
       "       -0.00000000e+00, -0.00000000e+00,  9.49904703e-02, -0.00000000e+00,\n",
       "        0.00000000e+00,  5.35200140e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  3.81345771e-02,  2.56715603e-03, -0.00000000e+00,\n",
       "        1.44492956e-02,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -2.75213273e-02, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -2.52526507e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -1.46452840e-03,  3.57396031e-02, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -2.99957529e-02,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -6.62139939e-03,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  4.79741702e-03, -0.00000000e+00, -1.49655392e-03,\n",
       "        7.54158588e-03,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -2.52768567e-02,\n",
       "        0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  5.10054790e-03,\n",
       "        0.00000000e+00,  2.93511096e-02,  0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "       -7.06484677e-02, -1.15166643e-01, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        7.93339641e-02,  0.00000000e+00,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  1.18469338e-01, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  4.53050141e-01, -0.00000000e+00,\n",
       "       -0.00000000e+00,  1.04304337e-01,  0.00000000e+00, -0.00000000e+00,\n",
       "        3.01648869e-02,  0.00000000e+00,  8.66201031e-01,  1.40492423e-01,\n",
       "        2.83080832e-02,  2.74925660e-01,  0.00000000e+00,  1.23387969e+00,\n",
       "        0.00000000e+00, -8.26473964e-03,  1.32359518e-01,  0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.53665603e-03, -0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
       "        4.71308056e-03,  0.00000000e+00, -9.67401785e-02, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00,  1.30633925e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "        0.00000000e+00,  5.00059857e-02,  0.00000000e+00, -2.72130296e-01,\n",
       "       -1.29658265e-01,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00,  6.51857271e-02,  0.00000000e+00,\n",
       "       -0.00000000e+00,  1.05830454e-02,  0.00000000e+00,  2.67595614e-02,\n",
       "       -0.00000000e+00,  2.44041211e-02,  0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00,  0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "        0.00000000e+00, -0.00000000e+00, -0.00000000e+00, -0.00000000e+00,\n",
       "       -0.00000000e+00,  0.00000000e+00, -0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor Variable</th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Absolute Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>579</th>\n",
       "      <td>COMBINED_SHOT_TYPE:jump_shot</td>\n",
       "      <td>1.233880</td>\n",
       "      <td>1.233880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>SHOT_TYPE:2pt_field_goal</td>\n",
       "      <td>0.866201</td>\n",
       "      <td>0.866201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>SHOT_ZONE_BASIC:restricted_area</td>\n",
       "      <td>0.453050</td>\n",
       "      <td>0.453050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>COMBINED_SHOT_TYPE:dunk</td>\n",
       "      <td>0.274926</td>\n",
       "      <td>0.274926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>ACTION_TYPE:jump_shot</td>\n",
       "      <td>-0.272130</td>\n",
       "      <td>0.272130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>SEASON_OPPONENT:mil:2009-10</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>SEASON_OPPONENT:mil:2008-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>SEASON_OPPONENT:mil:2007-08</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>SEASON_OPPONENT:mil:2006-07</td>\n",
       "      <td>-0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>643</th>\n",
       "      <td>CAREER_GAME_NUMBER</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>644 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Predictor Variable  Coefficient  Absolute Coefficient\n",
       "579     COMBINED_SHOT_TYPE:jump_shot     1.233880              1.233880\n",
       "574         SHOT_TYPE:2pt_field_goal     0.866201              0.866201\n",
       "566  SHOT_ZONE_BASIC:restricted_area     0.453050              0.453050\n",
       "577          COMBINED_SHOT_TYPE:dunk     0.274926              0.274926\n",
       "611            ACTION_TYPE:jump_shot    -0.272130              0.272130\n",
       "..                               ...          ...                   ...\n",
       "270      SEASON_OPPONENT:mil:2009-10    -0.000000              0.000000\n",
       "269      SEASON_OPPONENT:mil:2008-09     0.000000              0.000000\n",
       "268      SEASON_OPPONENT:mil:2007-08    -0.000000              0.000000\n",
       "267      SEASON_OPPONENT:mil:2006-07    -0.000000              0.000000\n",
       "643               CAREER_GAME_NUMBER     0.000000              0.000000\n",
       "\n",
       "[644 rows x 3 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef = pd.DataFrame({'Predictor Variable':X.columns, 'Coefficient':lasso_model.coef_, 'Absolute Coefficient':np.abs(lasso_model.coef_)})\n",
    "\n",
    "lasso_coef.sort_values('Absolute Coefficient', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Predictor Variable      508\n",
       "Coefficient             508\n",
       "Absolute Coefficient    508\n",
       "dtype: int64"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_coef[lasso_coef['Absolute Coefficient']==0].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1558, 644)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32605905006418484"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "508/1558"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "508"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((lasso_model.coef_==0)==True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variables zeroed out: 0.32605905006418484\n"
     ]
    }
   ],
   "source": [
    "print ('Percent variables zeroed out:', np.sum((lasso_model.coef_ == 0))/float(X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10) Find an optimal value for elastic net regression alpha using `ElasticNetCV`.\n",
    "\n",
    "Go to the documentation and [read how ElasticNetCV works](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNetCV.html).\n",
    "\n",
    "Note that here you'll be optimizing both the alpha parameter and the l1_ratio:\n",
    "- `alpha`: Strength of regularization.\n",
    "- `l1_ratio`: Amount of ridge vs. lasso (0 = all ridge, 1 = all lasso).\n",
    "    \n",
    "Do not include 0 in the search for `l1_ratio` — it won't allow it and will break.\n",
    "\n",
    "You can use `n_alphas` for the alpha parameters instead of setting your own values, which we highly recommend.\n",
    "\n",
    "Also, be careful setting too many l1_ratios over cross-validation folds in your search. It can take a long time if you choose too many combinations and, for the most part, there are diminishing returns in this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\redoc\\OneDrive\\Desktop\\DSI-Roughpaper\\3_02-lab-cross_validation_regularization-regression\\part_2-kobe-shots-made.ipynb Cell 53\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/redoc/OneDrive/Desktop/DSI-Roughpaper/3_02-lab-cross_validation_regularization-regression/part_2-kobe-shots-made.ipynb#Y120sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m enet_model \u001b[39m=\u001b[39m ElasticNetCV(l1_ratio\u001b[39m=\u001b[39menet_ratio, n_alphas \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/redoc/OneDrive/Desktop/DSI-Roughpaper/3_02-lab-cross_validation_regularization-regression/part_2-kobe-shots-made.ipynb#Y120sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Fit model using optimal alpha.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/redoc/OneDrive/Desktop/DSI-Roughpaper/3_02-lab-cross_validation_regularization-regression/part_2-kobe-shots-made.ipynb#Y120sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m enet_model \u001b[39m=\u001b[39m enet_model\u001b[39m.\u001b[39;49mfit(X_Scaled, y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/redoc/OneDrive/Desktop/DSI-Roughpaper/3_02-lab-cross_validation_regularization-regression/part_2-kobe-shots-made.ipynb#Y120sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# Generate predictions.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/redoc/OneDrive/Desktop/DSI-Roughpaper/3_02-lab-cross_validation_regularization-regression/part_2-kobe-shots-made.ipynb#Y120sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m enet_model_preds \u001b[39m=\u001b[39m enet_model\u001b[39m.\u001b[39mpredict(X_Scaled)\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1727\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1706\u001b[0m \u001b[39m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[0;32m   1707\u001b[0m \u001b[39m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[0;32m   1708\u001b[0m jobs \u001b[39m=\u001b[39m (\n\u001b[0;32m   1709\u001b[0m     delayed(_path_residuals)(\n\u001b[0;32m   1710\u001b[0m         X,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1725\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m folds\n\u001b[0;32m   1726\u001b[0m )\n\u001b[1;32m-> 1727\u001b[0m mse_paths \u001b[39m=\u001b[39m Parallel(\n\u001b[0;32m   1728\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[0;32m   1729\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[0;32m   1730\u001b[0m     prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1731\u001b[0m )(jobs)\n\u001b[0;32m   1732\u001b[0m mse_paths \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[39mlen\u001b[39m(folds), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m   1733\u001b[0m \u001b[39m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[0;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[0;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[0;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[1;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[0;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[0;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[0;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[0;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[1;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[0;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[0;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[0;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[0;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[1;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\joblib\\parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[0;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[1;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[1;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:1445\u001b[0m, in \u001b[0;36m_path_residuals\u001b[1;34m(X, y, sample_weight, train, test, normalize, fit_intercept, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[0;32m   1442\u001b[0m \u001b[39m# Do the ordering and type casting here, as if it is done in the path,\u001b[39;00m\n\u001b[0;32m   1443\u001b[0m \u001b[39m# X is copied and a reference is kept here\u001b[39;00m\n\u001b[0;32m   1444\u001b[0m X_train \u001b[39m=\u001b[39m check_array(X_train, accept_sparse\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcsc\u001b[39m\u001b[39m\"\u001b[39m, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39mX_order)\n\u001b[1;32m-> 1445\u001b[0m alphas, coefs, _ \u001b[39m=\u001b[39m path(X_train, y_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpath_params)\n\u001b[0;32m   1446\u001b[0m \u001b[39mdel\u001b[39;00m X_train, y_train\n\u001b[0;32m   1448\u001b[0m \u001b[39mif\u001b[39;00m y\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m   1449\u001b[0m     \u001b[39m# Doing this so that it becomes coherent with multioutput.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:634\u001b[0m, in \u001b[0;36menet_path\u001b[1;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[0;32m    632\u001b[0m     \u001b[39mif\u001b[39;00m check_input:\n\u001b[0;32m    633\u001b[0m         precompute \u001b[39m=\u001b[39m check_array(precompute, dtype\u001b[39m=\u001b[39mX\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mtype, order\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mC\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 634\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39;49menet_coordinate_descent_gram(\n\u001b[0;32m    635\u001b[0m         coef_,\n\u001b[0;32m    636\u001b[0m         l1_reg,\n\u001b[0;32m    637\u001b[0m         l2_reg,\n\u001b[0;32m    638\u001b[0m         precompute,\n\u001b[0;32m    639\u001b[0m         Xy,\n\u001b[0;32m    640\u001b[0m         y,\n\u001b[0;32m    641\u001b[0m         max_iter,\n\u001b[0;32m    642\u001b[0m         tol,\n\u001b[0;32m    643\u001b[0m         rng,\n\u001b[0;32m    644\u001b[0m         random,\n\u001b[0;32m    645\u001b[0m         positive,\n\u001b[0;32m    646\u001b[0m     )\n\u001b[0;32m    647\u001b[0m \u001b[39melif\u001b[39;00m precompute \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    648\u001b[0m     model \u001b[39m=\u001b[39m cd_fast\u001b[39m.\u001b[39menet_coordinate_descent(\n\u001b[0;32m    649\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[0;32m    650\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Set up a list of alphas to check.\n",
    "enet_alphas = np.linspace(0.01, 1.0, 25)\n",
    "\n",
    "# Set up our l1 ratio. (What does this do?)\n",
    "enet_ratio = enet_alphas\n",
    "\n",
    "# Instantiate model.\n",
    "enet_model = ElasticNetCV(l1_ratio=enet_ratio, n_alphas = 100, cv=10)\n",
    "\n",
    "# Fit model using optimal alpha.\n",
    "enet_model = enet_model.fit(X_Scaled, y)\n",
    "\n",
    "# Generate predictions.\n",
    "enet_model_preds = enet_model.predict(X_Scaled)\n",
    "enet_model_preds_train = enet_model.predict(X_Scaled)\n",
    "\n",
    "# Evaluate model.\n",
    "print(enet_model.score(X_Scaled, y))\n",
    "#print(enet_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0925"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enet_model.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................[Parallel(n_jobs=1)]: Done 250 out of 250 | elapsed:  2.5min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07271360998818006\n",
      "0.9587500000000001\n"
     ]
    }
   ],
   "source": [
    "l1_ratios = np.linspace(0.01, 1.0, 25)\n",
    "\n",
    "optimal_enet = ElasticNetCV(l1_ratio=l1_ratios, n_alphas=100, cv=10,\n",
    "                            verbose=1)\n",
    "optimal_enet.fit(X_Scaled, y)\n",
    "\n",
    "print (optimal_enet.alpha_)\n",
    "print (optimal_enet.l1_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 11) Cross-validate the elastic net $R^2$ with the optimal alpha and l1_ratio.\n",
    "\n",
    "How does it compare to the ridge and lasso regularized regressions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.61742795 0.52697978 0.53864379 0.61332045 0.54728018 0.55547707\n",
      " 0.52548033 0.4485161  0.46407359 0.52059974]\n",
      "0.5357798983416926\n"
     ]
    }
   ],
   "source": [
    "enet = ElasticNet(alpha=optimal_enet.alpha_, l1_ratio=optimal_enet.l1_ratio_)\n",
    "\n",
    "enet_scores = cross_val_score(enet, X_Scaled, y, cv=10)\n",
    "\n",
    "print (enet_scores)\n",
    "print (np.mean(enet_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 12. [Bonus] Compare the residuals for ridge and lasso visually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A: Maybe a jointplot?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1131d84b9e97d700f196cec3f143c1c5ca4787d89ba01101505d30befb8a4c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
