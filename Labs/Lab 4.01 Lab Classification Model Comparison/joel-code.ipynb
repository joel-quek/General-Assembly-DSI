{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 4, Lab 1: Predicting Left-Handedness from Psychological Factors\n",
    "> Author: Matt Brems\n",
    "\n",
    "We can sketch out the data science process as follows:\n",
    "1. Define the problem.\n",
    "2. Obtain the data.\n",
    "3. Explore the data.\n",
    "4. Model the data.\n",
    "5. Evaluate the model.\n",
    "6. Answer the problem.\n",
    "\n",
    "We'll walk through a full data science problem in this lab. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Define The Problem.\n",
    "\n",
    "You're currently a data scientist working at a university. A professor of psychology is attempting to study the relationship between personalities and left-handedness. They have tasked you with gathering evidence so that they may publish.\n",
    "\n",
    "Specifically, the professor says \"I need to prove that left-handedness is caused by some personality trait. Go find that personality trait and the data to back it up.\"\n",
    "\n",
    "As a data scientist, you know that any real data science problem must be **specific** and **conclusively answerable**. For example:\n",
    "- Bad data science problem: \"What is the link between obesity and blood pressure?\"\n",
    "    - This is vague and is not conclusively answerable. That is, two people might look at the conclusion and one may say \"Sure, the problem has been answered!\" and the other may say \"The problem has not yet been answered.\"\n",
    "- Good data science problem: \"Does an association exist between obesity and blood pressure?\"\n",
    "    - This is more specific and is conclusively answerable. The problem specifically is asking for a \"Yes\" or \"No\" answer. Based on that, two independent people should both be able to say either \"Yes, the problem has been answered\" or \"No, the problem has not yet been answered.\"\n",
    "- Excellent data science problem: \"As obesity increases, how does blood pressure change?\"\n",
    "    - This is very specific and is conclusively answerable. The problem specifically seeks to understand the effect of one variable on the other.\n",
    "\n",
    "### 1. In the context of the left-handedness and personality example, what are three specific and conclusively answerable problems that you could answer using data science? \n",
    "\n",
    "> You might find it helpful to check out the codebook in the repo for some inspiration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible Specific and Conclusively Answerable Problems\n",
    "\n",
    "1. Do individuals who give others handmade gifts, like to dance and decorate their things have a higher chance to be left-handed as compared to people who do not?\n",
    "\n",
    "2. Are males more likely to be left-handed than females?\n",
    "\n",
    "3. Are individuals who have higher education more likely to be left handed than those who are not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Obtain the data.\n",
    "\n",
    "### 2. Read in the file titled \"data.csv.\"\n",
    "> Hint: Despite being saved as a .csv file, you won't be able to simply `pd.read_csv()` this data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4184, 56)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>232</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6774</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1072</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>226</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1    1    1    5    5    5    1    5   \n",
       "1   1   5   1   4   2   5   5   4   1    5    2    5    3    4    1    4    1   \n",
       "2   1   2   1   1   5   4   3   2   1    4    4    5    4    3    4    1    2   \n",
       "3   1   4   1   5   1   4   5   4   3    5    1    3    2    3    1    5    2   \n",
       "4   5   1   5   1   5   1   5   1   3    1    1    1    5    5    5    1    5   \n",
       "\n",
       "   Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  Q29  Q30  Q31  Q32  \\\n",
       "0    1    5    1    5    1    1    1    5    5    5    1    5    1    1    1   \n",
       "1    1    1    5    2    4    4    4    1    2    1    2    1    3    1    5   \n",
       "2    3    1    3    3    3    4    5    3    2    2    2    1    4    3    3   \n",
       "3    2    5    5    2    3    2    2    1    4    1    1    1    3    4    1   \n",
       "4    1    5    2    5    1    5    1    5    5    5    1    5    1    5    1   \n",
       "\n",
       "   Q33  Q34  Q35  Q36  Q37  Q38  Q39  Q40  Q41  Q42  Q43  Q44  introelapse  \\\n",
       "0    1    5    5    1    1    1    5    5    5    1    5    1           91   \n",
       "1    2    4    4    4    4    4    1    3    1    4    4    5           17   \n",
       "2    4    4    2    2    4    2    1    4    2    2    2    2           11   \n",
       "3    3    5    5    1    3    4    1    2    1    1    1    3           14   \n",
       "4    5    5    5    1    1    1    5    5    5    1    5    1           10   \n",
       "\n",
       "   testelapse country  fromgoogle  engnat  age  education  gender  \\\n",
       "0         232      US           2       1   22          3       1   \n",
       "1         247      CA           2       1   14          1       2   \n",
       "2        6774      NL           2       2   30          4       1   \n",
       "3        1072      US           2       1   18          2       2   \n",
       "4         226      US           2       1   22          3       1   \n",
       "\n",
       "   orientation  race  religion  hand  \n",
       "0            1     3         2     3  \n",
       "1            2     6         1     1  \n",
       "2            1     1         1     2  \n",
       "3            5     3         2     2  \n",
       "4            1     3         2     3  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', 60)\n",
    "df = pd.read_csv('data.csv', delimiter='\\t' )\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Suppose that, instead of us giving you this data in a file, you were actually conducting a survey to gather this data yourself. From an ethics/privacy point of view, what are three things you might consider when attempting to gather this data?\n",
    "> When working with sensitive data like sexual orientation or gender identity, we need to consider how this data could be used if it fell into the wrong hands!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Any association regarding gender could lead to unhappy sentiments. For instance, if I say \"Males are more likely to be _____ than females.\" Depending on what word I use to fill in that blank, there will be unhappy people.\n",
    "\n",
    "2. Religion is also a touchy topic. To be honest, as religion is a nurture factor rather than nature factor, as a data scientist this parameter may fall into correlation rather than causation, so the use of religion as an independent variable might not be necessary.\n",
    "\n",
    "3. Likewise, race is also a touchy subject, with similar reasons as gender and religion, this parameter would cause certain unhappiness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Explore the data.\n",
    "\n",
    "### 4. Conduct exploratory data analysis on this dataset.\n",
    "> If you haven't already, be sure to check out the codebook in the repo, as that will help in your EDA process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4184 entries, 0 to 4183\n",
      "Data columns (total 56 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Q1           4184 non-null   int64 \n",
      " 1   Q2           4184 non-null   int64 \n",
      " 2   Q3           4184 non-null   int64 \n",
      " 3   Q4           4184 non-null   int64 \n",
      " 4   Q5           4184 non-null   int64 \n",
      " 5   Q6           4184 non-null   int64 \n",
      " 6   Q7           4184 non-null   int64 \n",
      " 7   Q8           4184 non-null   int64 \n",
      " 8   Q9           4184 non-null   int64 \n",
      " 9   Q10          4184 non-null   int64 \n",
      " 10  Q11          4184 non-null   int64 \n",
      " 11  Q12          4184 non-null   int64 \n",
      " 12  Q13          4184 non-null   int64 \n",
      " 13  Q14          4184 non-null   int64 \n",
      " 14  Q15          4184 non-null   int64 \n",
      " 15  Q16          4184 non-null   int64 \n",
      " 16  Q17          4184 non-null   int64 \n",
      " 17  Q18          4184 non-null   int64 \n",
      " 18  Q19          4184 non-null   int64 \n",
      " 19  Q20          4184 non-null   int64 \n",
      " 20  Q21          4184 non-null   int64 \n",
      " 21  Q22          4184 non-null   int64 \n",
      " 22  Q23          4184 non-null   int64 \n",
      " 23  Q24          4184 non-null   int64 \n",
      " 24  Q25          4184 non-null   int64 \n",
      " 25  Q26          4184 non-null   int64 \n",
      " 26  Q27          4184 non-null   int64 \n",
      " 27  Q28          4184 non-null   int64 \n",
      " 28  Q29          4184 non-null   int64 \n",
      " 29  Q30          4184 non-null   int64 \n",
      " 30  Q31          4184 non-null   int64 \n",
      " 31  Q32          4184 non-null   int64 \n",
      " 32  Q33          4184 non-null   int64 \n",
      " 33  Q34          4184 non-null   int64 \n",
      " 34  Q35          4184 non-null   int64 \n",
      " 35  Q36          4184 non-null   int64 \n",
      " 36  Q37          4184 non-null   int64 \n",
      " 37  Q38          4184 non-null   int64 \n",
      " 38  Q39          4184 non-null   int64 \n",
      " 39  Q40          4184 non-null   int64 \n",
      " 40  Q41          4184 non-null   int64 \n",
      " 41  Q42          4184 non-null   int64 \n",
      " 42  Q43          4184 non-null   int64 \n",
      " 43  Q44          4184 non-null   int64 \n",
      " 44  introelapse  4184 non-null   int64 \n",
      " 45  testelapse   4184 non-null   int64 \n",
      " 46  country      4184 non-null   object\n",
      " 47  fromgoogle   4184 non-null   int64 \n",
      " 48  engnat       4184 non-null   int64 \n",
      " 49  age          4184 non-null   int64 \n",
      " 50  education    4184 non-null   int64 \n",
      " 51  gender       4184 non-null   int64 \n",
      " 52  orientation  4184 non-null   int64 \n",
      " 53  race         4184 non-null   int64 \n",
      " 54  religion     4184 non-null   int64 \n",
      " 55  hand         4184 non-null   int64 \n",
      "dtypes: int64(55), object(1)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "      <td>4184.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.962715</td>\n",
       "      <td>3.829589</td>\n",
       "      <td>2.846558</td>\n",
       "      <td>3.186902</td>\n",
       "      <td>2.865440</td>\n",
       "      <td>3.672084</td>\n",
       "      <td>3.216539</td>\n",
       "      <td>3.184512</td>\n",
       "      <td>2.761233</td>\n",
       "      <td>3.522945</td>\n",
       "      <td>2.748805</td>\n",
       "      <td>2.852772</td>\n",
       "      <td>2.657505</td>\n",
       "      <td>3.334130</td>\n",
       "      <td>3.168021</td>\n",
       "      <td>2.930210</td>\n",
       "      <td>2.564771</td>\n",
       "      <td>3.424952</td>\n",
       "      <td>2.928537</td>\n",
       "      <td>3.639818</td>\n",
       "      <td>2.867591</td>\n",
       "      <td>3.595124</td>\n",
       "      <td>3.861138</td>\n",
       "      <td>3.337237</td>\n",
       "      <td>1.999761</td>\n",
       "      <td>3.001434</td>\n",
       "      <td>2.730641</td>\n",
       "      <td>2.624044</td>\n",
       "      <td>2.543738</td>\n",
       "      <td>2.894359</td>\n",
       "      <td>3.002151</td>\n",
       "      <td>2.869503</td>\n",
       "      <td>2.741874</td>\n",
       "      <td>3.022228</td>\n",
       "      <td>3.074092</td>\n",
       "      <td>2.610660</td>\n",
       "      <td>3.465344</td>\n",
       "      <td>2.798757</td>\n",
       "      <td>2.569312</td>\n",
       "      <td>2.984226</td>\n",
       "      <td>3.385277</td>\n",
       "      <td>2.704828</td>\n",
       "      <td>2.676386</td>\n",
       "      <td>2.736616</td>\n",
       "      <td>347.808556</td>\n",
       "      <td>479.994503</td>\n",
       "      <td>1.576243</td>\n",
       "      <td>1.239962</td>\n",
       "      <td>30.370698</td>\n",
       "      <td>2.317878</td>\n",
       "      <td>1.654398</td>\n",
       "      <td>1.833413</td>\n",
       "      <td>5.013623</td>\n",
       "      <td>2.394359</td>\n",
       "      <td>1.190966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.360291</td>\n",
       "      <td>1.551683</td>\n",
       "      <td>1.664804</td>\n",
       "      <td>1.476879</td>\n",
       "      <td>1.545798</td>\n",
       "      <td>1.342238</td>\n",
       "      <td>1.490733</td>\n",
       "      <td>1.387382</td>\n",
       "      <td>1.511805</td>\n",
       "      <td>1.242890</td>\n",
       "      <td>1.443078</td>\n",
       "      <td>1.556284</td>\n",
       "      <td>1.559575</td>\n",
       "      <td>1.522866</td>\n",
       "      <td>1.501683</td>\n",
       "      <td>1.575544</td>\n",
       "      <td>1.619010</td>\n",
       "      <td>1.413236</td>\n",
       "      <td>1.493122</td>\n",
       "      <td>1.414569</td>\n",
       "      <td>1.360858</td>\n",
       "      <td>1.354475</td>\n",
       "      <td>1.291425</td>\n",
       "      <td>1.426095</td>\n",
       "      <td>1.290747</td>\n",
       "      <td>1.480610</td>\n",
       "      <td>1.485883</td>\n",
       "      <td>1.481709</td>\n",
       "      <td>1.611428</td>\n",
       "      <td>1.477968</td>\n",
       "      <td>1.420032</td>\n",
       "      <td>1.659141</td>\n",
       "      <td>1.405670</td>\n",
       "      <td>1.562694</td>\n",
       "      <td>1.546400</td>\n",
       "      <td>1.409707</td>\n",
       "      <td>1.521460</td>\n",
       "      <td>1.413584</td>\n",
       "      <td>1.621772</td>\n",
       "      <td>1.483752</td>\n",
       "      <td>1.423055</td>\n",
       "      <td>1.544345</td>\n",
       "      <td>1.523097</td>\n",
       "      <td>1.471845</td>\n",
       "      <td>5908.901681</td>\n",
       "      <td>3142.178542</td>\n",
       "      <td>0.494212</td>\n",
       "      <td>0.440882</td>\n",
       "      <td>367.201726</td>\n",
       "      <td>0.874264</td>\n",
       "      <td>0.640915</td>\n",
       "      <td>1.303454</td>\n",
       "      <td>1.970996</td>\n",
       "      <td>2.184164</td>\n",
       "      <td>0.495357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>242.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>324.250000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>252063.000000</td>\n",
       "      <td>119834.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23763.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Q1           Q2           Q3           Q4           Q5  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      1.962715     3.829589     2.846558     3.186902     2.865440   \n",
       "std       1.360291     1.551683     1.664804     1.476879     1.545798   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     3.000000     1.000000     2.000000     1.000000   \n",
       "50%       1.000000     5.000000     3.000000     3.000000     3.000000   \n",
       "75%       3.000000     5.000000     5.000000     5.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "                Q6           Q7           Q8           Q9          Q10  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      3.672084     3.216539     3.184512     2.761233     3.522945   \n",
       "std       1.342238     1.490733     1.387382     1.511805     1.242890   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       3.000000     2.000000     2.000000     1.000000     3.000000   \n",
       "50%       4.000000     3.000000     3.000000     3.000000     4.000000   \n",
       "75%       5.000000     5.000000     4.000000     4.000000     5.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q11          Q12          Q13          Q14          Q15  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      2.748805     2.852772     2.657505     3.334130     3.168021   \n",
       "std       1.443078     1.556284     1.559575     1.522866     1.501683   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     1.000000     2.000000     2.000000   \n",
       "50%       3.000000     3.000000     3.000000     4.000000     3.000000   \n",
       "75%       4.000000     4.000000     4.000000     5.000000     5.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q16          Q17          Q18          Q19          Q20  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      2.930210     2.564771     3.424952     2.928537     3.639818   \n",
       "std       1.575544     1.619010     1.413236     1.493122     1.414569   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     1.000000     2.000000     2.000000     3.000000   \n",
       "50%       3.000000     2.000000     4.000000     3.000000     4.000000   \n",
       "75%       4.000000     4.000000     5.000000     4.000000     5.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q21          Q22          Q23          Q24          Q25  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      2.867591     3.595124     3.861138     3.337237     1.999761   \n",
       "std       1.360858     1.354475     1.291425     1.426095     1.290747   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     3.000000     3.000000     2.000000     1.000000   \n",
       "50%       3.000000     4.000000     4.000000     3.000000     1.000000   \n",
       "75%       4.000000     5.000000     5.000000     5.000000     3.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q26          Q27          Q28          Q29          Q30  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      3.001434     2.730641     2.624044     2.543738     2.894359   \n",
       "std       1.480610     1.485883     1.481709     1.611428     1.477968   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       3.000000     3.000000     3.000000     2.000000     3.000000   \n",
       "75%       4.000000     4.000000     4.000000     4.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q31          Q32          Q33          Q34          Q35  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      3.002151     2.869503     2.741874     3.022228     3.074092   \n",
       "std       1.420032     1.659141     1.405670     1.562694     1.546400   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       2.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "50%       3.000000     3.000000     3.000000     3.000000     3.000000   \n",
       "75%       4.000000     5.000000     4.000000     4.000000     5.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q36          Q37          Q38          Q39          Q40  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000   \n",
       "mean      2.610660     3.465344     2.798757     2.569312     2.984226   \n",
       "std       1.409707     1.521460     1.413584     1.621772     1.483752   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       1.000000     2.000000     1.000000     1.000000     2.000000   \n",
       "50%       2.000000     4.000000     3.000000     2.000000     3.000000   \n",
       "75%       4.000000     5.000000     4.000000     4.000000     4.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000     5.000000   \n",
       "\n",
       "               Q41          Q42          Q43          Q44    introelapse  \\\n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000    4184.000000   \n",
       "mean      3.385277     2.704828     2.676386     2.736616     347.808556   \n",
       "std       1.423055     1.544345     1.523097     1.471845    5908.901681   \n",
       "min       0.000000     0.000000     0.000000     0.000000       1.000000   \n",
       "25%       2.000000     1.000000     1.000000     1.000000       6.000000   \n",
       "50%       4.000000     3.000000     3.000000     3.000000      12.000000   \n",
       "75%       5.000000     4.000000     4.000000     4.000000      35.000000   \n",
       "max       5.000000     5.000000     5.000000     5.000000  252063.000000   \n",
       "\n",
       "          testelapse   fromgoogle       engnat           age    education  \\\n",
       "count    4184.000000  4184.000000  4184.000000   4184.000000  4184.000000   \n",
       "mean      479.994503     1.576243     1.239962     30.370698     2.317878   \n",
       "std      3142.178542     0.494212     0.440882    367.201726     0.874264   \n",
       "min         7.000000     1.000000     0.000000     13.000000     0.000000   \n",
       "25%       186.000000     1.000000     1.000000     18.000000     2.000000   \n",
       "50%       242.000000     2.000000     1.000000     21.000000     2.000000   \n",
       "75%       324.250000     2.000000     1.000000     27.000000     3.000000   \n",
       "max    119834.000000     2.000000     2.000000  23763.000000     4.000000   \n",
       "\n",
       "            gender  orientation         race     religion         hand  \n",
       "count  4184.000000  4184.000000  4184.000000  4184.000000  4184.000000  \n",
       "mean      1.654398     1.833413     5.013623     2.394359     1.190966  \n",
       "std       0.640915     1.303454     1.970996     2.184164     0.495357  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       1.000000     1.000000     5.000000     1.000000     1.000000  \n",
       "50%       2.000000     1.000000     6.000000     2.000000     1.000000  \n",
       "75%       2.000000     2.000000     6.000000     2.000000     1.000000  \n",
       "max       3.000000     5.000000     7.000000     7.000000     3.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Q1     0\n",
       "Q2     0\n",
       "Q31    0\n",
       "Q32    0\n",
       "Q33    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', 60)\n",
    "df.isnull().sum().sort_values(ascending=False)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there are no missing data in the dataframe. Thank you General Assembly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apart from country, which is the only categorical variable, all other variables have the integer datatype. The hot-encoding has been performed at the survey level. Thank you General Assembly for making my life easier.\n",
    "\n",
    "However I need to check what the unique values from the Country column are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA', 'NL', 'GR', 'GB', 'KR', 'SE', 'NO', 'DE', 'NZ', 'CH',\n",
       "       'RO', 'IL', 'IN', 'ZA', 'TR', 'JM', 'AU', 'BE', 'PL', 'CZ', 'RS',\n",
       "       'TW', 'A2', 'MX', 'PH', 'ES', 'AT', 'JP', 'IT', 'SG', 'MY', 'HK',\n",
       "       'FR', 'EU', 'DK', 'AE', 'EC', 'TH', 'IE', 'PK', 'BR', 'ID', 'EG',\n",
       "       'NI', 'FI', 'CN', 'RU', 'SI', 'AR', 'PT', 'LB', 'DO', 'PF', 'LT',\n",
       "       'BG', 'GE', 'CL', 'SK', 'EE', 'KE', 'UZ', 'LV', 'BB', 'BN', 'PR',\n",
       "       'HR', 'NP', 'A1', 'PE', 'UA', 'HU', 'VN', 'TZ', 'KH', 'UY', 'VE',\n",
       "       'IS', 'MP', 'CO', 'JO', 'TN', 'KW', 'CY', 'FJ', 'LK', 'VI', 'ZW',\n",
       "       'IM', 'ZM', 'QA', 'DZ', 'LY', 'SA'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df['country'].unique()))\n",
    "df['country'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will do a pairplot for the question dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Model the data.\n",
    "\n",
    "### 5. Suppose I wanted to use Q1 - Q44 to predict whether or not the person is left-handed. Would this be a classification or regression problem? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "It would be a classification problem because the dependent variable - whether a person is left-handed or otherwise, is a binary categorical variable. Meaning the answer is yes or no, and it is non-continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed based on their responses to Q1 - Q44. Before doing that, however, you remember that it is often a good idea to standardize your variables. In general, why would we standardize our variables? Give an example of when we would standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We standardize our variables when the data are on different scales. For example when we are comparing house prices like in Project 2, we can see that prices and square footage are on vastly different scales and square footage can go up to really large numbers. \n",
    "\n",
    "Scaling will make the data more manageable and easier to plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Give an example of when we might not standardize our variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We do not scale when the data are on the same scale. The best example would be the dataset for this lab. All questions are on the 5-point likend scale, so there is no need for scaling as they are consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Based on your answers to 6 and 7, do you think we should standardize our predictor variables in this case? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "We do not need to standardize as  they all follow the same 5-point likend scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. We want to use $k$-nearest neighbors to predict whether or not a person is left-handed. What munging/cleaning do we need to do to our $y$ variable in order to explicitly answer this question? Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>232</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>CA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6774</td>\n",
       "      <td>NL</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1072</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>226</td>\n",
       "      <td>US</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1    1    1    5    5    5    1    5   \n",
       "1   1   5   1   4   2   5   5   4   1    5    2    5    3    4    1    4    1   \n",
       "2   1   2   1   1   5   4   3   2   1    4    4    5    4    3    4    1    2   \n",
       "3   1   4   1   5   1   4   5   4   3    5    1    3    2    3    1    5    2   \n",
       "4   5   1   5   1   5   1   5   1   3    1    1    1    5    5    5    1    5   \n",
       "\n",
       "   Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  Q29  Q30  Q31  Q32  \\\n",
       "0    1    5    1    5    1    1    1    5    5    5    1    5    1    1    1   \n",
       "1    1    1    5    2    4    4    4    1    2    1    2    1    3    1    5   \n",
       "2    3    1    3    3    3    4    5    3    2    2    2    1    4    3    3   \n",
       "3    2    5    5    2    3    2    2    1    4    1    1    1    3    4    1   \n",
       "4    1    5    2    5    1    5    1    5    5    5    1    5    1    5    1   \n",
       "\n",
       "   Q33  Q34  Q35  Q36  Q37  Q38  Q39  Q40  Q41  Q42  Q43  Q44  introelapse  \\\n",
       "0    1    5    5    1    1    1    5    5    5    1    5    1           91   \n",
       "1    2    4    4    4    4    4    1    3    1    4    4    5           17   \n",
       "2    4    4    2    2    4    2    1    4    2    2    2    2           11   \n",
       "3    3    5    5    1    3    4    1    2    1    1    1    3           14   \n",
       "4    5    5    5    1    1    1    5    5    5    1    5    1           10   \n",
       "\n",
       "   testelapse country  fromgoogle  engnat  age  education  gender  \\\n",
       "0         232      US           2       1   22          3       1   \n",
       "1         247      CA           2       1   14          1       2   \n",
       "2        6774      NL           2       2   30          4       1   \n",
       "3        1072      US           2       1   18          2       2   \n",
       "4         226      US           2       1   22          3       1   \n",
       "\n",
       "   orientation  race  religion  hand  \n",
       "0            1     3         2     3  \n",
       "1            2     6         1     1  \n",
       "2            1     1         1     2  \n",
       "3            5     3         2     2  \n",
       "4            1     3         2     3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning Data**\n",
    "\n",
    "FYI: I need to clean the country column. Settle later. For now I drop the column first before making it into a one-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will hot-encode the 'country' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = df['country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'CA', 'NL', 'GR', 'GB', 'KR', 'SE', 'NO', 'DE', 'NZ', 'CH',\n",
       "       'RO', 'IL', 'IN', 'ZA', 'TR', 'JM', 'AU', 'BE', 'PL', 'CZ', 'RS',\n",
       "       'TW', 'A2', 'MX', 'PH', 'ES', 'AT', 'JP', 'IT', 'SG', 'MY', 'HK',\n",
       "       'FR', 'EU', 'DK', 'AE', 'EC', 'TH', 'IE', 'PK', 'BR', 'ID', 'EG',\n",
       "       'NI', 'FI', 'CN', 'RU', 'SI', 'AR', 'PT', 'LB', 'DO', 'PF', 'LT',\n",
       "       'BG', 'GE', 'CL', 'SK', 'EE', 'KE', 'UZ', 'LV', 'BB', 'BN', 'PR',\n",
       "       'HR', 'NP', 'A1', 'PE', 'UA', 'HU', 'VN', 'TZ', 'KH', 'UY', 'VE',\n",
       "       'IS', 'MP', 'CO', 'JO', 'TN', 'KW', 'CY', 'FJ', 'LK', 'VI', 'ZW',\n",
       "       'IM', 'ZM', 'QA', 'DZ', 'LY', 'SA'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SA\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "print(country_list[93])\n",
    "print(np.where(country_list=='NL')[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country Hot-Encoding Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'US': 0,\n",
       " 'CA': 1,\n",
       " 'NL': 2,\n",
       " 'GR': 3,\n",
       " 'GB': 4,\n",
       " 'KR': 5,\n",
       " 'SE': 6,\n",
       " 'NO': 7,\n",
       " 'DE': 8,\n",
       " 'NZ': 9,\n",
       " 'CH': 10,\n",
       " 'RO': 11,\n",
       " 'IL': 12,\n",
       " 'IN': 13,\n",
       " 'ZA': 14,\n",
       " 'TR': 15,\n",
       " 'JM': 16,\n",
       " 'AU': 17,\n",
       " 'BE': 18,\n",
       " 'PL': 19,\n",
       " 'CZ': 20,\n",
       " 'RS': 21,\n",
       " 'TW': 22,\n",
       " 'A2': 23,\n",
       " 'MX': 24,\n",
       " 'PH': 25,\n",
       " 'ES': 26,\n",
       " 'AT': 27,\n",
       " 'JP': 28,\n",
       " 'IT': 29,\n",
       " 'SG': 30,\n",
       " 'MY': 31,\n",
       " 'HK': 32,\n",
       " 'FR': 33,\n",
       " 'EU': 34,\n",
       " 'DK': 35,\n",
       " 'AE': 36,\n",
       " 'EC': 37,\n",
       " 'TH': 38,\n",
       " 'IE': 39,\n",
       " 'PK': 40,\n",
       " 'BR': 41,\n",
       " 'ID': 42,\n",
       " 'EG': 43,\n",
       " 'NI': 44,\n",
       " 'FI': 45,\n",
       " 'CN': 46,\n",
       " 'RU': 47,\n",
       " 'SI': 48,\n",
       " 'AR': 49,\n",
       " 'PT': 50,\n",
       " 'LB': 51,\n",
       " 'DO': 52,\n",
       " 'PF': 53,\n",
       " 'LT': 54,\n",
       " 'BG': 55,\n",
       " 'GE': 56,\n",
       " 'CL': 57,\n",
       " 'SK': 58,\n",
       " 'EE': 59,\n",
       " 'KE': 60,\n",
       " 'UZ': 61,\n",
       " 'LV': 62,\n",
       " 'BB': 63,\n",
       " 'BN': 64,\n",
       " 'PR': 65,\n",
       " 'HR': 66,\n",
       " 'NP': 67,\n",
       " 'A1': 68,\n",
       " 'PE': 69,\n",
       " 'UA': 70,\n",
       " 'HU': 71,\n",
       " 'VN': 72,\n",
       " 'TZ': 73,\n",
       " 'KH': 74,\n",
       " 'UY': 75,\n",
       " 'VE': 76,\n",
       " 'IS': 77,\n",
       " 'MP': 78,\n",
       " 'CO': 79,\n",
       " 'JO': 80,\n",
       " 'TN': 81,\n",
       " 'KW': 82,\n",
       " 'CY': 83,\n",
       " 'FJ': 84,\n",
       " 'LK': 85,\n",
       " 'VI': 86,\n",
       " 'ZW': 87,\n",
       " 'IM': 88,\n",
       " 'ZM': 89,\n",
       " 'QA': 90,\n",
       " 'DZ': 91,\n",
       " 'LY': 92,\n",
       " 'SA': 93}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_index_dict = {}\n",
    "for i in country_list:\n",
    "    country_index_dict[i] = np.where(country_list==i)[0][0]\n",
    "country_index_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map Dictionary to Hot-Encode Country Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['country']=df['country'].map(country_index_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Hot-Encoded Country Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        1\n",
       "2        2\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "4179     0\n",
       "4180     0\n",
       "4181    19\n",
       "4182     0\n",
       "4183     9\n",
       "Name: country, Length: 4184, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's perform the whole train/test split sequence with the new encoded dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model will include all columns except the hand column. I have not done the following yet\n",
    "1. Only include the question columns in the predictor dataframe\n",
    "2. Hot-encode the hand column to left handed versus the non left handed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['hand'], axis='columns')\n",
    "y = df['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.82686567, 0.8358209 , 0.84179104, 0.83880597, 0.83880597,\n",
       "       0.8358209 , 0.83880597, 0.84131737, 0.82634731, 0.83532934])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8359710429886495"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X_train, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to have a slightly weaker cross validation score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. The professor for whom you work suggests that you set $k = 4$. In this specific case, why might this be a bad idea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "Even numbers are not ideal because there is no tie-breaker when deciding which cluster to follow. Odd numbers are ideal as there will not be any indecision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Let's *(finally)* use $k$-nearest neighbors to predict whether or not a person is left-handed!\n",
    "\n",
    "> Be sure to create a train/test split with your data!\n",
    "\n",
    "> Create four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok i performed the default train test split above. Maybe now I scale the data.\n",
    "\n",
    "I will redo the train test split and use standard scaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The Default Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df.drop(['hand'], axis='columns')\n",
    "y = df['hand']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train_sc = ss.fit_transform(X_train)\n",
    "X_test_sc = ss.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.8358209 , 0.82686567, 0.84179104, 0.81791045, 0.83880597,\n",
       "       0.82985075, 0.8358209 , 0.83233533, 0.82934132, 0.84730539])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X_train_sc, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\redoc\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_split.py:684: UserWarning: The least populated class in y has only 9 members, which is less than n_splits=10.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8335847707569934"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(knn, X_train_sc, y_train, cv=10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four Separate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Four separate models, one with $k = 3$, one with $k = 5$, one with $k = 15$, and one with $k = 25$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot Encode Hand Column \n",
    "\n",
    "\"What hand do you use to write with?\" \t1=Right, 2=Left, 3=Both\n",
    "\n",
    "We need to focus on left-handed data and change left-handed coding to 1 and the rest to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['left']=[1 if i==2 else 0 for i in df['hand']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.891969\n",
       "1    0.108031\n",
       "Name: left, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['left'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 10% of the respondents are left-handed. Let us see if the question responses affect this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "      <th>Q29</th>\n",
       "      <th>Q30</th>\n",
       "      <th>Q31</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "      <th>Q42</th>\n",
       "      <th>Q43</th>\n",
       "      <th>Q44</th>\n",
       "      <th>introelapse</th>\n",
       "      <th>testelapse</th>\n",
       "      <th>country</th>\n",
       "      <th>fromgoogle</th>\n",
       "      <th>engnat</th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>gender</th>\n",
       "      <th>orientation</th>\n",
       "      <th>race</th>\n",
       "      <th>religion</th>\n",
       "      <th>hand</th>\n",
       "      <th>left</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>91</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>247</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>6774</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>1072</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>226</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  \\\n",
       "0   4   1   5   1   5   1   5   1   4    1    1    1    5    5    5    1    5   \n",
       "1   1   5   1   4   2   5   5   4   1    5    2    5    3    4    1    4    1   \n",
       "2   1   2   1   1   5   4   3   2   1    4    4    5    4    3    4    1    2   \n",
       "3   1   4   1   5   1   4   5   4   3    5    1    3    2    3    1    5    2   \n",
       "4   5   1   5   1   5   1   5   1   3    1    1    1    5    5    5    1    5   \n",
       "\n",
       "   Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28  Q29  Q30  Q31  Q32  \\\n",
       "0    1    5    1    5    1    1    1    5    5    5    1    5    1    1    1   \n",
       "1    1    1    5    2    4    4    4    1    2    1    2    1    3    1    5   \n",
       "2    3    1    3    3    3    4    5    3    2    2    2    1    4    3    3   \n",
       "3    2    5    5    2    3    2    2    1    4    1    1    1    3    4    1   \n",
       "4    1    5    2    5    1    5    1    5    5    5    1    5    1    5    1   \n",
       "\n",
       "   Q33  Q34  Q35  Q36  Q37  Q38  Q39  Q40  Q41  Q42  Q43  Q44  introelapse  \\\n",
       "0    1    5    5    1    1    1    5    5    5    1    5    1           91   \n",
       "1    2    4    4    4    4    4    1    3    1    4    4    5           17   \n",
       "2    4    4    2    2    4    2    1    4    2    2    2    2           11   \n",
       "3    3    5    5    1    3    4    1    2    1    1    1    3           14   \n",
       "4    5    5    5    1    1    1    5    5    5    1    5    1           10   \n",
       "\n",
       "   testelapse  country  fromgoogle  engnat  age  education  gender  \\\n",
       "0         232        0           2       1   22          3       1   \n",
       "1         247        1           2       1   14          1       2   \n",
       "2        6774        2           2       2   30          4       1   \n",
       "3        1072        0           2       1   18          2       2   \n",
       "4         226        0           2       1   22          3       1   \n",
       "\n",
       "   orientation  race  religion  hand  left  \n",
       "0            1     3         2     3     0  \n",
       "1            2     6         1     1     0  \n",
       "2            1     1         1     2     1  \n",
       "3            5     3         2     2     1  \n",
       "4            1     3         2     3     0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will only keep the question columns in the X dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df.iloc[:, 0:44] # only include the question columns\n",
    "\n",
    "X = df.drop(columns=['introelapse', 'testelapse', 'country',\n",
    "       'fromgoogle', 'engnat', 'age', 'education', 'gender', 'orientation',\n",
    "       'race', 'religion', 'hand', 'left'], axis = 1)\n",
    "\n",
    "y = df['left']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KIV \n",
    "\n",
    "What is model_selection and why test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=30)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=30)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=30)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k_3 = KNeighborsClassifier(n_neighbors = 3)\n",
    "k_3.fit(X_train, y_train)\n",
    "\n",
    "k_5 = KNeighborsClassifier(n_neighbors = 5)\n",
    "k_5.fit(X_train, y_train)\n",
    "\n",
    "k_15 = KNeighborsClassifier(n_neighbors = 15)\n",
    "k_15.fit(X_train, y_train)\n",
    "\n",
    "k_25 = KNeighborsClassifier(n_neighbors = 25)\n",
    "k_25.fit(X_train, y_train)\n",
    "\n",
    "k_30 = KNeighborsClassifier(n_neighbors = 30)\n",
    "k_30.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Being good data scientists, we know that we might not run just one type of model. We might run many different models and see which is best.\n",
    "\n",
    "### 12. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, let's check the [documentation for logistic regression in sklearn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html). Is there default regularization? If so, what is it? If not, how do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer: \n",
    "\n",
    "The default Regularization is L2 regularization. It is mentioned in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. We want to use logistic regression to predict whether or not a person is left-handed. Before we do that, should we standardize our features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I would not scale as the data are on the same scale. The questions are all on the same 5 point scale."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 14. Let's use logistic regression to predict whether or not the person is left-handed.\n",
    "\n",
    "\n",
    "> Be sure to use the same train/test split with your data as with your $k$-NN model above!\n",
    "\n",
    "> Create four separate models, one with LASSO and $\\alpha = 1$, one with LASSO and $\\alpha = 10$, one with Ridge and $\\alpha = 1$, and one with Ridge and $\\alpha = 10$. *(Hint: Be careful with how you specify $\\alpha$ in your model!)*\n",
    "\n",
    "> Instantiate and fit your models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: In sklearn.linear_model.LogisticRegression, L1 is Lasso and L2 is Ridge\n",
    "\n",
    "https://towardsdatascience.com/l1-and-l2-regularization-methods-ce25e7fc831c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=.25, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C in the LogisticRegression object is the \n",
    "\n",
    "**Inverse of regularization strength** ${alpha}$ ; must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.1)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##'''\n",
    "lasso_1 = LogisticRegression(C=1, penalty='l1', solver='liblinear')\n",
    "lasso_1.fit(X_train, y_train)\n",
    "\n",
    "lasso_10 = LogisticRegression(C=0.1, penalty='l1', solver='liblinear')\n",
    "lasso_10.fit(X_train, y_train)\n",
    "\n",
    "ridge_1 = LogisticRegression(penalty ='l2', C = 1.0)\n",
    "ridge_1.fit(X_train, y_train)\n",
    "\n",
    "ridge_10 = LogisticRegression(penalty ='l2', C = 0.1)\n",
    "ridge_10.fit(X_train, y_train)\n",
    "##'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above did not work initially and kept returning \"ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\"\n",
    "\n",
    "Source: https://stackoverflow.com/questions/60868629/valueerror-solver-lbfgs-supports-only-l2-or-none-penalties-got-l1-penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Version 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=10)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate.\n",
    "ridge_model_1 = Ridge(alpha=1)\n",
    "ridge_model_10 = Ridge(alpha=10)\n",
    "lasso_model_1 = Lasso(alpha=1)\n",
    "lasso_model_10 = Lasso(alpha=10)\n",
    "\n",
    "\n",
    "# Fit.\n",
    "ridge_model_1.fit(X_train, y_train)\n",
    "ridge_model_10.fit(X_train, y_train)\n",
    "lasso_model_1.fit(X_train, y_train)\n",
    "lasso_model_10.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Evaluate the model(s).\n",
    "\n",
    "### 15. Before calculating any score on your data, take a step back. Think about your $X$ variable and your $Y$ variable. Do you think your $X$ variables will do a good job of predicting your $Y$ variable? Why or why not? What impact do you think this will have on your scores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "The X variables are answers to questions that are hihgly independent from each other. Moreover, these questions are non-physiological and thus should not contribute to whether or not a person is left handed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 16. Using accuracy as your metric, evaluate all eight of your models on both the training and testing sets. Put your scores below. (If you want to be fancy and generate a table in Markdown, there's a [Markdown table generator site linked here](https://www.tablesgenerator.com/markdown_tables#).)\n",
    "- Note: Your answers here might look a little weird. You didn't do anything wrong; that's to be expected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate KNN Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Version 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K3 Score is: 0.8549988807716572\n",
      "K5 Score is: 0.8776235729838628\n",
      "K15 Score is: 0.8919700453796219\n",
      "K25 Score is: 0.8919700453796219\n",
      "K30 Score is: 0.8919700453796219\n"
     ]
    }
   ],
   "source": [
    "print(f\"K3 Score is: {cross_val_score(k_3, X_train, y_train, cv=10).mean()}\")\n",
    "\n",
    "print(f\"K5 Score is: {cross_val_score(k_5, X_train, y_train, cv=10).mean()}\")\n",
    "\n",
    "print(f\"K15 Score is: {cross_val_score(k_15, X_train, y_train, cv=10).mean()}\")\n",
    "\n",
    "print(f\"K25 Score is: {cross_val_score(k_25, X_train, y_train, cv=10).mean()}\")\n",
    "\n",
    "print(f\"K30 Score is: {cross_val_score(k_30, X_train, y_train, cv=10).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Version 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why so different outputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9031230082855322\n",
      "0.8932441045251752\n",
      "0.8916507329509241\n",
      "0.8919694072657743\n"
     ]
    }
   ],
   "source": [
    "print(k_3.score(X_train, y_train))\n",
    "print(k_5.score(X_train, y_train))\n",
    "print(k_15.score(X_train, y_train))\n",
    "print(k_25.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.861376673040153\n",
      "0.884321223709369\n",
      "0.8919694072657743\n",
      "0.8919694072657743\n"
     ]
    }
   ],
   "source": [
    "print(k_3.score(X_test, y_test))\n",
    "print(k_5.score(X_test, y_test))\n",
    "print(k_15.score(X_test, y_test))\n",
    "print(k_25.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The outputs are very weird."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Logistic Regression Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922880815806246\n",
      "0.8919694072657743\n",
      "0.8919694072657743\n",
      "0.8919694072657743\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using R2.\n",
    "print(ridge_1.score(X_train, y_train))\n",
    "print(ridge_1.score(X_test, y_test))\n",
    "\n",
    "print(ridge_10.score(X_train, y_train))\n",
    "print(ridge_10.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8922880815806246\n",
      "0.8919694072657743\n",
      "0.8922880815806246\n",
      "0.8919694072657743\n"
     ]
    }
   ],
   "source": [
    "print(lasso_1.score(X_train, y_train))\n",
    "print(lasso_1.score(X_test, y_test))\n",
    "\n",
    "print(lasso_10.score(X_train, y_train))\n",
    "print(lasso_10.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.020045527417619557\n",
      "-0.009430445754212702\n",
      "0.020045305464253427\n",
      "-0.009356239389057386\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model using R2.\n",
    "print(ridge_model_1.score(X_train, y_train))\n",
    "print(ridge_model_1.score(X_test, y_test))\n",
    "\n",
    "print(ridge_model_10.score(X_train, y_train))\n",
    "print(ridge_model_10.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(lasso_model_1.score(X_train, y_train))\n",
    "print(lasso_model_1.score(X_test, y_test))\n",
    "\n",
    "print(lasso_model_10.score(X_train, y_train))\n",
    "print(lasso_model_10.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version 2 outputs are wierd. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Markdown Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- KNN version 2\n",
    "- Logistic Regression Version 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Model|k value|Penalty|Alpha|Training Accuracy|Testing Accuracy|\n",
    "|---|---|---|---|---|---|\n",
    "|K3|3|-|-|0.9037603569152326|0.8738049713193117|\n",
    "|K5|5|-|-|0.8951561504142767|0.8881453154875717|\n",
    "|K15|15|-|-|0.8919694072657743|0.8919694072657743|\n",
    "|K25|25|-|-|0.8919694072657743|0.8919694072657743|\n",
    "|Log Reg|-|RIDGE|1|0.8922880815806246|0.8919694072657743|\n",
    "|Log Reg|-|RIDGE|10|0.8919694072657743|0.8919694072657743|\n",
    "|Log Reg|-|LASSO|1|0.8922880815806246|0.8919694072657743|\n",
    "|Log Reg|-|LASSO|10|0.8922880815806246|0.8922880815806246|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My outputs are damn weird. But I will use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 17. In which of your $k$-NN models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Overfitting happens when the training score is higher than the test score.\n",
    "\n",
    "K3 and K5 are overfitted.\n",
    "\n",
    "K15 and K25 look perfect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 18. Broadly speaking, how does the value of $k$ in $k$-NN affect the bias-variance tradeoff? (i.e. As $k$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "As k increases, we have a more stable model, i.e., smaller variance, however, the bias is also increased. As k decreases, the bias also decreases, but the model is less stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 19. If you have a $k$-NN model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. If I wish to decrease overfitting, it means I wish to decrease variance. So I must incease K.\n",
    "\n",
    "The other two I dont really know."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 20. In which of your logistic regression models is there evidence of overfitting? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Damn weird, they all have similar training scores and similar testing scores.\n",
    "\n",
    "Training scores arer higher than the testing scores, so there is overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. Broadly speaking, how does the value of $C$ in logistic regression affect the bias-variance tradeoff? (i.e. As $C$ increases, how are bias and variance affected?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "- C is a hyperparameter. C is inversely proportional to the Lambda regulator.\n",
    "\n",
    "- As C decreases, Lambda Increases and we regularize more, the coefficients will be cut/decrease to zero\n",
    "If we regularize more, then our variance decreases and our bias increases. Hence underfitting.\n",
    "\n",
    "- As C increases, Lambda Decreases and we regularize less, the coefficients will be close to their original values.\n",
    "If we regularize less, then out variance increases and bias decreases. Hence overfitting.\n",
    "\n",
    "Source: \n",
    "\n",
    "https://www.quora.com/What-is-the-C-parameter-in-logistic-regression\n",
    "\n",
    "https://www.r-bloggers.com/2017/07/machine-learning-explained-regularization/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: https://towardsdatascience.com/regularization-the-path-to-bias-variance-trade-off-b7a7088b4577#:~:text=Regularization%20will%20help%20select%20a,need%20of%20the%20trade%2Doff.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/640/1*v63L_h5WXGOb4o6oh_daAA.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "print(\"Source: https://towardsdatascience.com/regularization-the-path-to-bias-variance-trade-off-b7a7088b4577#:~:text=Regularization%20will%20help%20select%20a,need%20of%20the%20trade%2Doff.\")\n",
    "Image(url= \"https://miro.medium.com/max/640/1*v63L_h5WXGOb4o6oh_daAA.jpeg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://miro.medium.com/max/720/1*Myo0GHpJGbVgNcL5bdFXzQ.jpeg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://miro.medium.com/max/720/1*Myo0GHpJGbVgNcL5bdFXzQ.jpeg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. For your logistic regression models, play around with the regularization hyperparameter, $C$. As you vary $C$, what happens to the fit and coefficients in the model? What do you think this means in the context of this specific problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "From our analysis, we can see that the change in Lambda values did not change the train/test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03879107,  0.02597124,  0.05046773, -0.09654074,  0.05487369,\n",
       "        -0.03371421,  0.01423638, -0.20621719, -0.06437082,  0.01016808,\n",
       "        -0.01379565,  0.02976638, -0.02617966,  0.00981023, -0.0236182 ,\n",
       "         0.03342182,  0.01814875, -0.04684967, -0.026438  , -0.02720384,\n",
       "        -0.1021382 , -0.05243714, -0.04688922,  0.00640949,  0.00934487,\n",
       "         0.14652407,  0.05782262,  0.03830185,  0.04684627,  0.0256385 ,\n",
       "        -0.00060334, -0.04048914,  0.0112108 , -0.06094644,  0.02897012,\n",
       "         0.01564155, -0.03069409,  0.08533659, -0.05555764, -0.07890389,\n",
       "        -0.05317497, -0.07935506, -0.10381217, -0.02448749]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03777074,  0.02501265,  0.04915075, -0.09437106,  0.05369493,\n",
       "        -0.03337471,  0.0134103 , -0.19792384, -0.06314589,  0.00951155,\n",
       "        -0.01345096,  0.02885192, -0.02576752,  0.00900495, -0.02340238,\n",
       "         0.03240696,  0.01796146, -0.04604425, -0.02637987, -0.02709659,\n",
       "        -0.09510947, -0.05152243, -0.04650195,  0.00584055,  0.00940259,\n",
       "         0.14347131,  0.04676145,  0.03766074,  0.04571283,  0.02519899,\n",
       "        -0.00080912, -0.04024056,  0.0104528 , -0.05981963,  0.0279672 ,\n",
       "         0.01492459, -0.03051511,  0.08308649, -0.05422689, -0.07628666,\n",
       "        -0.05249057, -0.0779042 , -0.0927881 , -0.02415086]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_10.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. If you have a logistic regression model that has evidence of overfitting, what are three things you might try to do to combat overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "1. Gather more data\n",
    "\n",
    "2. Regularize using LASSO or RIDGE\n",
    "\n",
    "I don't know.\n",
    "\n",
    "https://statisticsbyjim.com/regression/overfitting-regression-models/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Answer the problem.\n",
    "\n",
    "### 24. Suppose you want to understand which psychological features are most important in determining left-handedness. Would you rather use $k$-NN or logistic regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I would choose logistic regression because it determines the probability of an individual being left handed or righthanded. K-NN seems more deterministic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. Select your logistic regression model that utilized LASSO regularization with $\\alpha = 1$. Interpret the coefficient for `Q1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03854365,  0.02148247,  0.04829938, -0.09406896,  0.05311773,\n",
       "        -0.03326281,  0.0101832 , -0.20842658, -0.06332732,  0.00425097,\n",
       "        -0.01459002,  0.02567652, -0.02827035,  0.0063521 , -0.02076704,\n",
       "         0.03055252,  0.01771509, -0.04671134, -0.02747075, -0.02732012,\n",
       "        -0.10515037, -0.05195853, -0.04683461,  0.00196206,  0.00514742,\n",
       "         0.14401482,  0.03941315,  0.03697849,  0.04462493,  0.02313028,\n",
       "        -0.0015909 , -0.03937838,  0.00445421, -0.06002593,  0.02594534,\n",
       "         0.0113916 , -0.03103752,  0.08174287, -0.05224724, -0.07547087,\n",
       "        -0.05306921, -0.07691185, -0.08596716, -0.02288492]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_1.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer to lecture 4.01. I need to use np.exp to get the actual values of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96218971, 1.02171488, 1.0494848 , 0.91021999, 1.0545538 ,\n",
       "        0.96728432, 1.01023523, 0.81186064, 0.93863619, 1.00426002,\n",
       "        0.9855159 , 1.026009  , 0.97212551, 1.00637231, 0.97944711,\n",
       "        1.03102404, 1.01787293, 0.95436284, 0.97290314, 0.9730497 ,\n",
       "        0.90018915, 0.94936823, 0.95424521, 1.00196399, 1.00516069,\n",
       "        1.15490123, 1.04020016, 1.0376707 , 1.0456356 , 1.02339986,\n",
       "        0.99841036, 0.96138687, 1.00446415, 0.94174012, 1.02628485,\n",
       "        1.01145673, 0.9694392 , 1.08517674, 0.94909419, 0.92730674,\n",
       "        0.94831438, 0.92597148, 0.91762437, 0.97737495]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(lasso_1.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient for Q1 is 0.9621 that means \n",
    "\n",
    "- if the value of Q1 increases by 1, the log-odds of someone being left handed decreases by 0.0385\n",
    "- if the value of Q1 increases by 1, someone is 96.22% likely to be left-handed\n",
    "\n",
    "Refer to lecture 4.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. If you have to select one model overall to be your *best* model, which model would you select? Why?\n",
    "- Usually in the \"real world,\" you'll fit many types of models but ultimately need to pick only one! (For example, a client may not understand what it means to have multiple models, or if you're using an algorithm to make a decision, it's probably pretty challenging to use two or more algorithms simultaneously.) It's not always an easy choice, but you'll have to make it soon enough. Pick a model and defend why you picked this model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "I would select the model with the best bias-variance trade-off.\n",
    "\n",
    "That would mean any of my logistic regression models would be the best choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. Circle back to the three specific and conclusively answerable questions you came up with in Q1. Answer one of these for the professor based on the model you selected!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:\n",
    "\n",
    "Do individuals who give others handmade gifts, like to dance and decorate their things have a higher chance to be left-handed as compared to people who do not?\n",
    "\n",
    "Check Q4, Q40, Q44 Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9102199949275407\n",
      "0.927306744255856\n",
      "0.9773749510150815\n"
     ]
    }
   ],
   "source": [
    "print(np.exp((lasso_1.coef_)[0][3]))\n",
    "print(np.exp((lasso_1.coef_)[0][39]))\n",
    "print(np.exp((lasso_1.coef_)[0][43]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that as the answer to these questions increase, so does the likelihood of left-handedness. There is an effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS:\n",
    "Looking for more to do? Probably not - you're busy! But if you want to, consider exploring the following. (They could make for a blog post!)\n",
    "- Create a visual plot comparing training and test metrics for various values of $k$ and various regularization schemes in logistic regression.\n",
    "- Rather than just evaluating models based on accuracy, consider using sensitivity, specificity, etc.\n",
    "- In the context of predicting left-handedness, why are unbalanced classes concerning? If you were to re-do this process given those concerns, what changes might you make?\n",
    "- Fit and evaluate a generalized linear model other than logistic regression (e.g. Poisson regression).\n",
    "- Suppose this data were in a `SQL` database named `data` and a table named `inventory`. What `SQL` query would return the count of people who were right-handed, left-handed, both, or missing with their class labels of 1, 2, 3, and 0, respectively? (You can assume you've already logged into the database.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f1131d84b9e97d700f196cec3f143c1c5ca4787d89ba01101505d30befb8a4c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
